{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Classification**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification adalah area yang sangat penting dalam supervised machine learning. Sejumlah besar masalah supervised machine learning yang penting termasuk dalam area ini. Ada banyak metode classification, dan Logistic Regression dan K-NN adalah salah satunya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is Classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised machine learning algorithms menentukan model yang menangkap hubungan di antara data. Classification adalah area supervised machine learning yang mencoba memprediksi kelas atau kategori mana dari suatu entitas, berdasarkan fitur-fiturnya.\n",
    "\n",
    "Misalnya, kita mungkin menganalisis karyawan beberapa perusahaan dan mencoba membangun ketergantungan pada fitur atau variabel, seperti tingkat pendidikan, jumlah tahun bekerja di posisi saat ini, usia, gaji, peluang untuk dipromosikan, dan sebagainya. Kumpulan data yang terkait dengan satu karyawan adalah satu observasi. Fitur atau variabel dapat berupa salah satu dari dua bentuk:\n",
    "- Independent variables, also called inputs or predictors, don’t depend on other features of interest (or at least you assume so for the purpose of the analysis).\n",
    "- Dependent variables, also called outputs or responses, depend on the independent variables.\n",
    "\n",
    "Dalam contoh di atas, saat kita menganalisis karyawan, kita mungkin menganggap tingkat pendidikan, waktu di posisi saat ini, dan usia sebagai saling independen, dan menganggap mereka sebagai inputs. Gaji dan peluang promosi bisa menjadi hasil yang bergantung pada masukan.\n",
    "\n",
    "Sifat dependent variables membedakan masalah regression dan classification. Masalah regression memiliki keluaran yang berkelanjutan dan biasanya tidak terbatas. Contohnya adalah saat kita memperkirakan gaji sebagai fungsi dari pengalaman dan tingkat pendidikan. Di sisi lain, masalah classification memiliki keluaran diskrit dan terbatas yang disebut kelas atau kategori. Misalnya, memprediksi apakah seorang karyawan akan dipromosikan atau tidak (benar atau salah) adalah masalah klasifikasi.\n",
    "\n",
    "Ada dua jenis masalah klasifikasi:\n",
    "- Binary or binomial classification: exactly two classes to choose between (usually 0 and 1, true and false, or positive and negative)\n",
    "- Multiclass or multinomial classification: three or more classes of the outputs to choose from\n",
    "\n",
    "Jika hanya ada satu variabel masukan, biasanya ini dilambangkan dengan 𝑥. Untuk lebih dari satu masukan, kita biasanya akan melihat notasi vektor 𝐱 = (𝑥₁,…, 𝑥ᵣ), di mana 𝑟 adalah jumlah predictors (atau fitur independen). Variabel keluaran sering dilambangkan dengan 𝑦 dan mengambil nilai 0 atau 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Do You Need Classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat menerapkan klasifikasi di banyak bidang sains dan teknologi. Misalnya, text classification algorithms digunakan untuk memisahkan email yang bukan spam dan spam, serta komentar positif dan negatif. Contoh lain melibatkan aplikasi medis, klasifikasi biologis, penilaian kredit, dan banyak lagi.\n",
    "\n",
    "Image recognition sering kali direpresentasikan sebagai masalah klasifikasi. Misalnya, kita mungkin bertanya apakah suatu gambar menggambarkan wajah manusia atau bukan, atau apakah itu tikus atau gajah, atau digit mana dari nol sampai sembilan yang diwakilinya, dan seterusnya.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebelum mendalami Logistic Regression, penting untuk mengingat kembali beberapa pemahaman dasar tentang Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/bb7/30d/6ef/1604379363131.jpg?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression dapat sangat berguna saat kita mencoba memprediksi nilai keluaran continuous dari linear relationship. Tetapi nilai keluaran Logistic Regression berada di antara 0 dan 1. Karenanya, output continuous value yang tidak berada dalam kisaran antara 0 dan 1 tidak berfungsi dengan Logistic Regression.\n",
    "\n",
    "Lihat gambar di atas untuk contoh model regresi linier. Titik biru adalah titik data kita dan garis merah adalah model kita.\n",
    "\n",
    "Linear Regression menggunakan pengukuran statistik seperti R² dan p-value untuk memahami kinerja model dan variabel yang melatih model.\n",
    "- R² is used to indicate if there is a correlation between the dependent variable and a particular independent variable. In other words, does the the independent variable help determine the dependent variable.\n",
    "- P-value is used to determine if R² is statistically significance.\n",
    "- Lastly you should know that the cost function of linear regression is Mean Squared Error.\n",
    "\n",
    "Cara kerja logistic regression adalah memprediksi probabilitas sampel kita termasuk dalam satu klasifikasi versus klasifikasi lainnya. Meskipun dapat digunakan untuk klasifikasi multivariabel, ini adalah alat yang hebat untuk digunakan untuk masalah klasifikasi biner karena beroperasi pada probabilitas. Nilai keluaran dalam logistic regression adalah klasifikasi bernomor, tetapi sebelum klasifikasi diberikan, keluaran yang AKTUAL adalah probabilitas numerik dalam rentang 0 sampai 1. Berdasarkan probabilitas tersebut akan diberikan klasifikasi 1 atau 0. Algoritme pada dasarnya membulatkan nilai untuk memberikan klasifikasi; 0 adalah kelas negatif dan 1 adalah kelas positif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/1db/d7f/6a1/1604379378753.jpg?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Logistic Regression\n",
    "\n",
    "1. Binary Logistic Regression:\n",
    "Variabel dependen hanya memiliki dua kemungkinan hasil / kelas.\n",
    "Example-Male or Female.\n",
    "2. Multinomial Logistic Regression:\n",
    "Variabel dependen hanya memiliki dua kemungkinan hasil / kelas 3 atau lebih tanpa urutan.\n",
    "Example: Predicting food quality.(Good,Great and Bad).\n",
    "3. Ordinal Logistic Regression:\n",
    "Variabel dependen hanya memiliki dua 3 atau lebih kemungkinan hasil / kelas dengan pengurutan. Example: Star rating from 1 to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sigmoid Function**\n",
    "\n",
    "Kita perlu memahami linear regression karena logistic regression juga menggunakan persamaan linier dengan variabel independen untuk memprediksi nilai keluaran (probabilitas). Kasus penggunaannya (classification vs. forecasting) adalah yang pada akhirnya membedakan satu sama lain.\n",
    "\n",
    "Meskipun Logistic Regression menggunakan persamaan linier, pembedanya adalah sigmoid function. Sigmoid function adalah fungsi matematika yang memiliki karakteristik kurva berbentuk \"S\".\n",
    "\n",
    "Fungsi matematis sigmoid ditunjukkan di bawah ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/ece/ea3/940/1604379447572.jpg?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dan pada gambar dibawah adalah standard linear function kita yang memerlukan konstanta dan nilai input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/0b5/c56/ad8/1604379447699.jpg?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang pada gambar dibawah, kitamemasukkan persamaan linier ke dalam fungsi sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/f8a/b7e/cfd/1604379448846.jpg?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the output(z) of the linear equation and give to the function g(x) which returns a squashed value h, the value h will lie in the range of 0 to 1. To understand how sigmoid function squashes the values within the range, let’s visualize the graph of the sigmoid function.\n",
    "\n",
    "Gambar ini menunjukkan fungsi sigmoid (atau kurva berbentuk S) dari beberapa variabel 𝑥:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.realpython.com/media/log-reg-1.e32deaa7cbac.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function memiliki nilai yang sangat dekat dengan 0 atau 1 di sebagian besar domainnya. Fakta ini membuatnya cocok untuk aplikasi dalam metode classification.\n",
    "\n",
    "**Natural Logarithm**\n",
    "\n",
    "Gambar ini menggambarkan natural logarithm log(𝑥) dari beberapa variabel 𝑥, untuk nilai 𝑥 antara 0 dan 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.realpython.com/media/log-reg-4.81e9806a86fa.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ketika 𝑥 mendekati nol, logaritma natural dari 𝑥 turun menuju tak terhingga negatif. Ketika 𝑥 = 1, log (𝑥) adalah 0. Kebalikannya berlaku untuk log (1 - 𝑥).\n",
    "\n",
    "Perhatikan bahwa kita akan sering menemukan natural logarithm yang dilambangkan dengan ln , bukan log. Dalam Python, math.log(x) dan numpy.log(x) mewakili natural logarithm dari x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam sesi ini, kita  akan melihat penjelasan untuk kasus umum logistic regression yang diterapkan pada binary classification. Saat kita menerapkan logistic regression dari beberapa variabel dependen 𝑦 pada kumpulan variabel independen 𝐱 = (𝑥₁,…, 𝑥ᵣ), dengan 𝑟 adalah jumlah prediktor (atau input), kita mulai dengan nilai prediktor yang diketahui 𝐱ᵢ dan respon aktual yang sesuai (atau keluaran) 𝑦ᵢ untuk setiap observasi 𝑖 = 1,…, 𝑛.\n",
    "\n",
    "Tujuan kita adalah menemukan logistic regression function 𝑝 (𝐱) sedemikian rupa sehingga predicted responses 𝑝 (𝐱ᵢ) sedekat mungkin dengan actual response 𝑦ᵢ untuk setiap pengamatan 𝑖 = 1,…, 𝑛. Ingatlah bahwa respons sebenarnya hanya bisa 0 atau 1 dalam binary classification problems! Ini berarti bahwa setiap 𝑝 (𝐱ᵢ) harus mendekati 0 atau 1. Itulah mengapa lebih mudah menggunakan fungsi sigmoid.\n",
    "\n",
    "Setelah kita memiliki fungsi regresi logistik 𝑝 (𝐱), kita dapat menggunakannya untuk memprediksi keluaran untuk masukan baru dan yang tidak terlihat, dengan asumsi bahwa ketergantungan matematika yang mendasarinya tidak berubah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Methodology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression adalah linear classifier, jadi kita akan menggunakan fungsi linier 𝑓(𝐱) = 𝑏₀ + 𝑏₁𝑥₁ + ⋯ + 𝑏ᵣ𝑥ᵣ, juga disebut logit. Variabel 𝑏₀, 𝑏₁,…, 𝑏ᵣ adalah estimators dari regression coefficients, yang juga disebut predicted weights atau coefficients.\n",
    "\n",
    "Logistic regression function 𝑝 (𝐱) adalah fungsi sigmoid dari 𝑓(𝐱): 𝑝 (𝐱) = 1 / (1 + exp (−𝑓(𝐱)). Oleh karena itu, sering kali mendekati 0 atau 1. Fungsi 𝑝(𝐱) sering diartikan sebagai predicted probability yang mana output untuk 𝐱 yang diberikan sama dengan 1. Oleh karena itu, 1 - 𝑝(𝑥) adalah probabilitas yang outputnya adalah 0.\n",
    "\n",
    "Logistic regression menentukan bobot prediksi terbaik 𝑏₀, 𝑏₁,…, 𝑏ᵣ sedemikian rupa sehingga fungsi 𝑝(𝐱) sedekat mungkin dengan semua actual responses 𝑦ᵢ, 𝑖 = 1,…, 𝑛, di mana 𝑛 adalah jumlah observasi. Proses penghitungan bobot terbaik menggunakan observasi yang tersedia disebut model training atau fitting.\n",
    "\n",
    "Untuk mendapatkan bobot terbaik, biasanya kita memaksimalkan log-likelihood function (LLF) untuk semua observasi 𝑖 = 1,…, 𝑛. Metode ini disebut maximum likelihood estimation dan diwakili oleh persamaan LLF = Σᵢ(𝑦ᵢ log (𝑝(𝐱ᵢ)) + (1 - 𝑦ᵢ) log (1 - 𝑝(𝐱ᵢ))).\n",
    "\n",
    "Jika 𝑦ᵢ = 0, LLF pengamatan terkait sama dengan log (1 - 𝑝(𝐱ᵢ)). Jika 𝑝(𝐱ᵢ) mendekati 𝑦ᵢ = 0, maka log (1 - 𝑝(𝐱ᵢ)) mendekati 0. Ini adalah hasil yang kita inginkan. Jika 𝑝(𝐱ᵢ) jauh dari 0, maka log (1 - 𝑝(𝐱ᵢ)) turun secara signifikan. Kita tidak menginginkan hasil itu karena tujuan kita adalah mendapatkan LLF maksimum. Demikian pula, jika 𝑦ᵢ = 1, LLF untuk pengamatan tersebut adalah 𝑦ᵢ log(𝑝(𝐱ᵢ)). Jika 𝑝(𝐱ᵢ) mendekati 𝑦ᵢ = 1, maka log (𝑝(𝐱ᵢ)) mendekati 0. Jika 𝑝 (𝐱ᵢ) jauh dari 1, maka log (𝑝 (𝐱ᵢ)) adalah bilangan negatif yang besar.\n",
    "\n",
    "Ada beberapa pendekatan matematis yang akan menghitung bobot terbaik yang sesuai dengan LLF maksimum, tetapi itu di luar cakupan sesi ini.\n",
    "\n",
    "Setelah kita menentukan bobot terbaik yang menentukan fungsi 𝑝(𝐱), kita bisa mendapatkan predicted outputs 𝑝(𝐱ᵢ) untuk masukan yang diberikan 𝐱ᵢ. Untuk setiap observasi 𝑖 = 1,…, 𝑛, predicted output adalah 1 jika 𝑝(𝐱ᵢ)> 0,5 dan 0 sebaliknya. Ambang batasnya tidak harus 0,5, tetapi biasanya memang begitu. Kita dapat menentukan nilai yang lebih rendah atau lebih tinggi jika itu lebih nyaman untuk situasi kita.\n",
    "\n",
    "Ada satu hubungan penting lagi antara 𝑝(𝐱) dan 𝑓(𝐱), yaitu log (𝑝(𝐱) / (1 - 𝑝(𝐱))) = 𝑓(𝐱). Persamaan ini menjelaskan mengapa 𝑓(𝐱) adalah logit. Ini menyiratkan bahwa 𝑝(𝐱) = 0,5 ketika 𝑓(𝐱) = 0 dan output yang diprediksi adalah 1 jika 𝑓(𝐱)> 0 dan 0 sebaliknya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Classification Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification memiliki empat kemungkinan jenis hasil:\n",
    "- True negatives: correctly predicted negatives (zeros)\n",
    "- True positives: correctly predicted positives (ones)\n",
    "- False negatives: incorrectly predicted negatives (zeros)\n",
    "- False positives: incorrectly predicted positives (ones)\n",
    "\n",
    "Kita biasanya mengevaluasi kinerja pengklasifikasi kita dengan membandingkan actual and predicted outputs serta menghitung prediksi yang benar dan yang salah.\n",
    "\n",
    "Indikator classification accuracy yang paling jelas adalah rasio jumlah prediksi yang benar dengan jumlah total prediksi (atau observasi). Indikator lain dari binary classifiers adalah sebagai berikut:\n",
    "- The positive predictive value is the ratio of the number of true positives to the sum of the numbers of true and false positives.\n",
    "- The negative predictive value is the ratio of the number of true negatives to the sum of the numbers of true and false negatives.\n",
    "- The sensitivity (also known as recall or true positive rate) is the ratio of the number of true positives to the number of actual positives.\n",
    "- The specificity (or true negative rate) is the ratio of the number of true negatives to the number of actual negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single-Variate Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-variate logistic regression adalah kasus logistic regression yang paling jelas. Hanya ada satu variabel independen (atau fitur), yaitu 𝐱 = 𝑥. Gambar ini mengilustrasikan single-variate logistic regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.realpython.com/media/log-reg-2.e88a21607ba3.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D Logistic Regression\n",
    "\n",
    "Di sini, kita memiliki satu set pasangan input-output (atau 𝑥-𝑦), yang diwakili oleh lingkaran hijau. Ini adalah pengamatan kita. Ingatlah bahwa 𝑦 hanya bisa 0 atau 1. Misalnya, lingkaran hijau paling kiri memiliki masukan 𝑥 = 0 dan keluaran aktual 𝑦 = 0. Pengamatan paling kanan memiliki 𝑥 = 9 dan 𝑦 = 1.\n",
    "\n",
    "Logistic regression menemukan bobot 𝑏₀ dan 𝑏₁ yang sesuai dengan maximum LLF. Bobot ini menentukan logit 𝑓 (𝑥) = 𝑏₀ + 𝑏₁𝑥, yang merupakan garis hitam putus-putus. Mereka juga menentukan predicted probability 𝑝 (𝑥) = 1 / (1 + exp (−𝑓 (𝑥))), yang ditampilkan di sini sebagai garis hitam. Dalam hal ini, threshold 𝑝 (𝑥) = 0,5 dan 𝑓 (𝑥) = 0 sesuai dengan nilai 𝑥 sedikit lebih tinggi dari 3. Nilai ini adalah batas antara input dengan output yang diprediksi 0 dan 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Variate Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-variate logistic regression memiliki lebih dari satu variabel masukan. Gambar ini menunjukkan klasifikasi dengan dua variabel independen, 𝑥₁ dan 𝑥₂:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.realpython.com/media/log-reg-3.b1634d335c4f.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D Logistic Regression\n",
    "\n",
    "Grafik ini berbeda dengan grafik single-variate karena kedua sumbu mewakili input. Outputnya juga berbeda dalam warna. Lingkaran putih menunjukkan observasi yang diklasifikasikan sebagai nol, sedangkan lingkaran hijau adalah yang diklasifikasikan sebagai satu.\n",
    "\n",
    "Logistic regression menentukan bobot 𝑏₀, 𝑏₁, dan 𝑏₂ yang memaksimalkan LLF. Setelah kita memiliki 𝑏₀, 𝑏₁, dan 𝑏₂, kita bisa mendapatkan:\n",
    "- The logit 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂\n",
    "- The probabilities 𝑝(𝑥₁, 𝑥₂) = 1 / (1 + exp(−𝑓(𝑥₁, 𝑥₂)))\n",
    "\n",
    "Garis hitam putus-putus memisahkan kedua kelas secara linier. Garis ini sesuai dengan 𝑝 (𝑥₁, 𝑥₂) = 0,5 dan 𝑓 (𝑥₁, 𝑥₂) = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression in Python**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression in Python With scikit-learn: Example 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh pertama terkait dengan single-variate binary classification problem. Ini adalah jenis masalah klasifikasi yang paling jelas. Ada beberapa langkah umum yang harus kita ambil saat menyiapkan model klasifikasi:\n",
    "- Import packages, functions, and classes\n",
    "- Get data to work with and, if appropriate, transform it\n",
    "- Create a classification model and train (or fit) it with your existing data\n",
    "- Evaluate your model to see if its performance is satisfactory\n",
    "\n",
    "Model yang cukup baik yang kita tentukan dapat digunakan untuk membuat prediksi lebih lanjut terkait dengan data baru yang tidak terlihat. Prosedur di atas sama untuk klasifikasi dan regresi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Import Packages, Functions, and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pertama, kita harus mengimpor Matplotlib untuk visualisasi dan NumPy untuk operasi array.\n",
    "\n",
    "Kita juga akan memerlukan LogisticRegression, classification_report(), dan confusion_matrix() dari scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Get Data In practice, you’ll usually have some data to work with. For the purpose of this example, let’s just create arrays for the input (𝑥) and output (𝑦) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input dan output harus berupa array NumPy (instance kelas numpy.ndarray) atau objek serupa. numpy.arange() membuat array nilai yang berurutan dan berjarak sama dalam rentang tertentu.\n",
    "\n",
    "Array x harus dua dimensi. Array x harus memiliki satu kolom untuk setiap masukan, dan jumlah baris harus sama dengan jumlah observations. Untuk membuat x dua dimensi, kita menerapkan .reshape() dengan argumen -1 untuk mendapatkan baris sebanyak yang diperlukan dan 1 untuk mendapatkan satu kolom. Beginilah tampilan x dan y sekarang:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]] [0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x memiliki dua dimensi:\n",
    "- Satu kolom untuk satu masukan\n",
    "- Sepuluh baris, masing-masing sesuai dengan satu pengamatan\n",
    "\n",
    "y adalah satu dimensi dengan sepuluh item. Sekali lagi, setiap item berhubungan dengan satu observasi. Ini hanya berisi nol dan satu karena ini adalah masalah klasifikasi biner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Create a Model and Train It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah kita menyiapkan input dan output, kita dapat membuat dan menentukan model klasifikasi. Kita akan membuatnya dengan instance kelas LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pernyataan di atas membuat instance LogisticRegression dan mengikat referensinya ke variabel model. LogisticRegression memiliki beberapa parameter opsional yang menentukan perilaku dan pendekatan model:\n",
    "- penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "- dual is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n",
    "- tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "- C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "- fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept 𝑏₀ (when True) or consider it equal to zero (when False).\n",
    "- intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept 𝑏₀.\n",
    "- class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "- random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "- solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "- max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
    "- multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "- verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n",
    "- warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
    "- n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
    "- l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.\n",
    "\n",
    "Kita harus mencocokkan solver dan regularization dengan hati-hati karena beberapa alasan:\n",
    "- 'liblinear' solver doesn’t work without regularization.\n",
    "- 'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
    "- 'saga' is the only solver that supports elastic-net regularization.\n",
    "\n",
    "Setelah model dibuat, kita perlu menyesuaikan (atau melatih) model tersebut. Model fitting adalah proses menentukan koefisien 𝑏₀, 𝑏₁,…, 𝑏ᵣ yang sesuai dengan best value of the cost function. Kita melatih model dengan .fit():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=1.0,\n",
    "                   class_weight=None,\n",
    "                   dual=False,\n",
    "                   fit_intercept=True,\n",
    "                   intercept_scaling=1,\n",
    "                   l1_ratio=None,\n",
    "                   max_iter=100,\n",
    "                   multi_class='auto',\n",
    "                   n_jobs=None,\n",
    "                   penalty='l2',\n",
    "                   random_state=0,\n",
    "                   solver='liblinear',\n",
    "                   tol=0.0001,\n",
    "                   verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pernyataan diatas sama dengan dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear',\n",
    "                           random_state=0).fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada titik ini, kita telah membuat model klasifikasi.\n",
    "\n",
    "Kita bisa dengan cepat mendapatkan atribut model kita. Misalnya, atribut .classes_ mewakili array nilai berbeda yang diambil y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ini adalah contoh klasifikasi biner, dan y bisa menjadi 0 atau 1, seperti yang ditunjukkan di atas.\n",
    "\n",
    "Kita juga bisa mendapatkan nilai slope 𝑏₁ dan titik intercept 𝑏₀ dari linear function 𝑓 seperti ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.04608067] [[0.51491375]]\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti yang kita lihat, 𝑏₀ diberikan di dalam array satu dimensi, sedangkan 𝑏₁ ada di dalam array dua dimensi. Kita menggunakan atribut .intercept_ dan .coef_ untuk mendapatkan hasil ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah model ditentukan, kita dapat memeriksa performanya dengan .predict_proba(), yang mengembalikan matriks probabilitas bahwa keluaran yang diprediksi sama dengan nol atau satu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74002157, 0.25997843],\n",
       "       [0.62975524, 0.37024476],\n",
       "       [0.5040632 , 0.4959368 ],\n",
       "       [0.37785549, 0.62214451],\n",
       "       [0.26628093, 0.73371907],\n",
       "       [0.17821501, 0.82178499],\n",
       "       [0.11472079, 0.88527921],\n",
       "       [0.07186982, 0.92813018],\n",
       "       [0.04422513, 0.95577487],\n",
       "       [0.02690569, 0.97309431]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam matriks di atas, setiap baris sesuai dengan satu observasi. Kolom pertama adalah probabilitas keluaran yang diprediksi menjadi nol, yaitu 1 - 𝑝(𝑥). Kolom kedua adalah probabilitas yang outputnya satu, atau 𝑝(𝑥).\n",
    "\n",
    "Kita bisa mendapatkan prediksi aktual, berdasarkan matriks probabilitas dan nilai 𝑝(𝑥), dengan .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi ini mengembalikan nilai keluaran yang diprediksi sebagai one-dimensional array.\n",
    "\n",
    "Gambar di bawah ini mengilustrasikan input, output, dan hasil klasifikasi:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.realpython.com/media/log-reg-5.1e0f3f7e733a.png?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lingkaran hijau mewakili actual responses prediksi yang benar. × merah menunjukkan prediksi yang salah. Garis hitam  adalah perkiraan logistic regression line 𝑝 (𝑥). Kotak abu-abu adalah titik-titik pada garis ini yang sesuai dengan 𝑥 dan nilai-nilai di kolom kedua dari matriks probabilitas. Garis putus-putus hitam adalah logit 𝑓(𝑥).\n",
    "\n",
    "Nilai 𝑥 sedikit di atas 2 sesuai dengan threshold 𝑝 (𝑥) = 0,5, yaitu 𝑓 (𝑥) = 0. Nilai 𝑥 ini adalah batas antara titik yang diklasifikasikan sebagai nol dan yang diprediksi sebagai titik.\n",
    "\n",
    "Misalnya, titik pertama memiliki masukan 𝑥 = 0, keluaran aktual 𝑦 = 0, probabilitas 𝑝 = 0,26, dan nilai prediksi 0. Titik kedua memiliki 𝑥 = 1, 𝑦 = 0, 𝑝 = 0,37, dan prediksi 0. Hanya poin keempat yang memiliki output aktual 𝑦 = 0 dan probabilitas lebih tinggi dari 0,5 (pada 𝑝 = 0,62), jadi salah diklasifikasikan sebagai 1. Semua nilai lainnya diprediksi dengan benar.\n",
    "\n",
    "Jika kita memiliki sembilan dari sepuluh observasi yang diklasifikasikan dengan benar, akurasi model kita sama dengan 9/10 = 0,9, yang dapat kita peroleh dengan .score():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".score() mengambil input dan output sebagai argumen dan mengembalikan rasio jumlah prediksi yang benar dengan jumlah observasi.\n",
    "\n",
    "Kita bisa mendapatkan lebih banyak informasi tentang keakuratan model dengan confusion matrix. Dalam kasus klasifikasi biner, confusion matrix menunjukkan angka-angka berikut ini:\n",
    "- True negatives in the upper-left position\n",
    "- False negatives in the lower-left position\n",
    "- False positives in the upper-right position\n",
    "- True positives in the lower-right position\n",
    "\n",
    "Untuk membuat confusion matrix, kita bisa menggunakan confusion_matrix() dan memberikan actual dan predicted outputs sebagai argumen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriks yang diperoleh menunjukkan hasil sebagai berikut:\n",
    "- Three true negative predictions: The first three observations are zeros predicted correctly.\n",
    "- No false negative predictions: These are the ones wrongly predicted as zeros.\n",
    "- One false positive prediction: The fourth observation is a zero that was wrongly predicted as one.\n",
    "- Six true positive predictions: The last six observations are ones predicted correctly.\n",
    "\n",
    "Seringkali berguna untuk memvisualisasikan confusion matrix. kita dapat melakukannya dengan .imshow() dari Matplotlib, yang menerima confusion matrix sebagai argumen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada gambar ini, warna berbeda mewakili angka berbeda dan warna serupa mewakili angka serupa. Heatmaps adalah cara yang bagus untuk merepresentasikan matriks.\n",
    "\n",
    "Kita bisa mendapatkan laporan yang lebih komprehensif tentang klasifikasi dengan classification_report():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 5** : Improve the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat meningkatkan model  dengan mengatur parameter yang berbeda. Misalnya, mari bekerja dengan regularization strength C sama dengan 10,0, daripada nilai default 1,0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10.0, random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10.0, random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',\n",
    "                           C=10.0,\n",
    "                           random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.51335372] [[1.12066084]]\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression(C=10.0,\n",
    "                   class_weight=None,\n",
    "                   dual=False,\n",
    "                   fit_intercept=True,\n",
    "                   intercept_scaling=1,\n",
    "                   l1_ratio=None,\n",
    "                   max_iter=100,\n",
    "                   multi_class='auto',\n",
    "                   n_jobs=None,\n",
    "                   penalty='l2',\n",
    "                   random_state=0,\n",
    "                   solver='liblinear', \n",
    "                   tol=0.0001,\n",
    "                   verbose=0,\n",
    "                   warm_start=False)\n",
    "print(model.intercept_, model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97106534 0.02893466]\n",
      " [0.9162684  0.0837316 ]\n",
      " [0.7810904  0.2189096 ]\n",
      " [0.53777071 0.46222929]\n",
      " [0.27502212 0.72497788]\n",
      " [0.11007743 0.88992257]\n",
      " [0.03876835 0.96123165]\n",
      " [0.01298011 0.98701989]\n",
      " [0.0042697  0.9957303 ]\n",
      " [0.00139621 0.99860379]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_proba(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti yang kita lihat, absolute values dari intercept  𝑏₀ dan coefficient 𝑏₁ lebih besar. Ini terjadi karena nilai C yang lebih besar berarti regularisasi yang lebih lemah, atau penalti yang lebih lemah terkait dengan nilai 𝑏₀ dan 𝑏₁ yang tinggi.\n",
    "\n",
    "Nilai 𝑏₀ dan 𝑏₁ yang berbeda menyiratkan perubahan logit 𝑓(𝑥), nilai probabilitas 𝑝 (𝑥) yang berbeda, bentuk garis regresi yang berbeda, dan kemungkinan perubahan dalam hasil prediksi dan kinerja klasifikasi lainnya. Nilai batas 𝑥 yang mana 𝑝 (𝑥) = 0,5 dan 𝑓 (𝑥) = 0 sekarang lebih tinggi, di atas 3. Dalam hal ini, kita mendapatkan semua prediksi yang benar, seperti yang ditunjukkan oleh akurasi, confusion matrix, dan classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score (atau accuracy) 1 dan angka nol di kolom kiri bawah dan kanan atas dari confusion matrixmenunjukkan bahwa actual dan predicted outputs sama. Hal itu juga ditunjukkan dengan gambar di bawah ini:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.realpython.com/media/log-reg-7.9141027bd736.png?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gambar ini mengilustrasikan bahwa estimated regression line kini memiliki bentuk yang berbeda dan titik keempat diklasifikasikan dengan benar sebagai 0. Tidak ada tanda × merah, jadi tidak ada prediksi yang salah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression in Python: Handwriting Recognition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh sebelumnya mengilustrasikan implementasi logistic regression dengan Python, serta beberapa detail terkait metode ini. Contoh berikutnya akan menunjukkan cara menggunakan logistic regression untuk memecahkan real-world classification problem. Pendekatannya sangat mirip dengan yang kita lihat, tetapi dengan kumpulan data yang lebih besar dan beberapa masalah tambahan.\n",
    "\n",
    "Contoh ini adalah tentang image recognition. Untuk lebih tepatnya, kita akan bekerja pada recognition atas handwritten digits. Kita akan menggunakan kumpulan data dengan 1797 observasi, yang masing-masing berupa gambar dari satu digit tulisan tangan. Setiap gambar memiliki 64 px, dengan lebar 8 px dan tinggi 8 px.\n",
    "\n",
    "Input (𝐱) adalah vektor dengan 64 dimensi atau nilai. Setiap vektor input menggambarkan satu gambar. Masing-masing dari 64 nilai mewakili satu piksel gambar. Nilai input adalah bilangan bulat antara 0 dan 16, bergantung pada shade of gray untuk piksel yang sesuai. Output (𝑦) untuk setiap observasi adalah bilangan bulat antara 0 dan 9, konsisten dengan digit pada gambar. Ada total sepuluh kelas, masing-masing sesuai dengan satu gambar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita perlu mengimpor Matplotlib, NumPy, dan beberapa fungsi dan kelas dari scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2a: Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita bisa mengambil dataset langsung dari scikit-learn dengan load_digits(). Ini mengembalikan tuple input dan output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itu adalah data yang kita dapatkan untuk dikerjakan. x adalah multi-dimensional array dengan 1797 baris dan 64 kolom. x berisi bilangan bulat dari 0 hingga 16. y adalahone-dimensional array dengan 1797 bilangan bulat antara 0 dan 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2b: Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merupakan praktik yang baik dan diterapkan secara luas untuk membagi kumpulan data yang kita kerjakan menjadi dua subkumpulan. Subkumpulan tersebut adalah training set dan test set. Pembagian ini biasanya dilakukan secara acak. Kita harus menggunakan training set untuk melatih model kita . Setelah model dilatih, kita mengevaluasi kinerjanya dengan test set. Penting untuk tidak menggunakan test set dalam proses training model. Pendekatan ini memungkinkan evaluasi model yang tidak bias.\n",
    "\n",
    "Salah satu cara untuk membagi set data kita menjadi training set dan test set adalah dengan menerapkan train_test_split():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split() menerima x dan y. train_test_split() juga membutuhkan test_size, yang menentukan ukuran test set, dan random_state untuk menentukan status pseudo-random number generator, serta argumen opsional lainnya. Fungsi ini mengembalikan list dengan empat array:\n",
    "- x_train: the part of x used to fit the model\n",
    "- x_test: the part of x used to evaluate the model\n",
    "- y_train: the part of y that corresponds to x_train\n",
    "- y_test: the part of y that corresponds to x_test\n",
    "\n",
    "Setelah data kita terbagi, kita bisa menghiraukan x_test dan y_test sampai kita membuat model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2c: Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization adalah proses mengubah data sedemikian rupa sehingga mean tiap kolom menjadi sama dengan nol, dan standard deviation tiap kolom adalah satu. Dengan cara ini, kita mendapatkan skala yang sama untuk semua kolom. Lakukan langkah-langkah berikut untuk menstandarkan data:\n",
    "- Calculate the mean and standard deviation for each column.\n",
    "- Subtract the corresponding mean from each element.\n",
    "- Divide the obtained difference by the corresponding standard deviation.\n",
    "\n",
    "Merupakan praktik yang baik untuk standardize  data input yang kita gunakan untuk logistic regression, meskipun dalam banyak kasus hal itu tidak diperlukan. Standardization dapat meningkatkan kinerja algoritme kita. Ini membantu jika kita perlu compare dan interpret weights.\n",
    "\n",
    "Kita bisa standardize input dengan membuat instance StandardScaler dan memanggil .fit_transform() di atasnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".fit_transform() menyesuaikan instance StandardScaler ke array yang diteruskan sebagai argumen, mengubah array ini, dan mengembalikan array standar yang baru. Sekarang, x_train adalah array input standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create a Model and Train It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah ini sangat mirip dengan contoh sebelumnya. Satu-satunya perbedaan adalah kita  menggunakan subset x_train dan y_train agar sesuai dengan model. Sekali lagi, kita harus membuat instance LogisticRegression dan memanggil .fit() di atasnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.05, multi_class=&#x27;ovr&#x27;, random_state=0,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.05, multi_class=&#x27;ovr&#x27;, random_state=0,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.05, multi_class='ovr', random_state=0,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',\n",
    "                           C=0.05,\n",
    "                           multi_class='ovr',\n",
    "                           random_state=0)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.05, multi_class=&#x27;ovr&#x27;, random_state=0,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.05, multi_class=&#x27;ovr&#x27;, random_state=0,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.05, multi_class='ovr', random_state=0,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=0.05,\n",
    "                   class_weight=None,\n",
    "                   dual=False,\n",
    "                   fit_intercept=True,\n",
    "                   intercept_scaling=1,\n",
    "                   l1_ratio=None,\n",
    "                   max_iter=100,\n",
    "                   multi_class='ovr',\n",
    "                   n_jobs=None,\n",
    "                   penalty='l2',\n",
    "                   random_state=0,\n",
    "                   solver='liblinear',\n",
    "                   tol=0.0001,\n",
    "                   verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita harus mengevaluasi model seperti yang kita lakukan pada contoh sebelumnya, dengan perbedaan bahwa kita sebagian besar akan menggunakan x_test dan y_test, yang merupakan subkumpulan yang tidak diterapkan untuk training. Jika kita telah memutuskan untuk menstandarkan x_train, maka model yang diperoleh bergantung pada scaled data, jadi x_test harus diskalakan juga dengan instance StandardScaler yang sama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begitulah cara kita  mendapatkan x_test baru dengan skala yang tepat. Dalam kasus ini, kita menggunakan .transform(), yang hanya mengubah argumen, tanpa menyesuaikan scaler.\n",
    "\n",
    "Kita bisa mendapatkan predicted outputs dengan .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variabel y_pred sekarang terikat ke array predicted outputs. Perhatikan bahwa kita menggunakan x_test sebagai argumen di sini.\n",
    "\n",
    "Kita bisa mendapatkan akurasi dengan .score():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964509394572025"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebenarnya, kita bisa mendapatkan dua nilai akurasi, satu diperoleh dengan training set dan lainnya dengan test set. Sebaiknya membandingkan keduanya, karena situasi di mana akurasi set pelatihan jauh lebih tinggi mungkin mengindikasikan overfitting. Akurasi set pengujian lebih relevan untuk mengevaluasi performa pada data yang tidak terlihat karena tidak bias.\n",
    "\n",
    "Kita bisa mendapatkan confusion matrix dengan confusion_matrix():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 32,  0,  0,  0,  0,  1,  0,  1,  1],\n",
       "       [ 1,  1, 33,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1, 28,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 29,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 39,  0,  0,  0,  1],\n",
       "       [ 0,  1,  0,  0,  0,  0, 43,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 39,  0,  0],\n",
       "       [ 0,  2,  1,  2,  0,  0,  0,  1, 33,  0],\n",
       "       [ 0,  0,  0,  1,  0,  1,  0,  2,  1, 36]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix yang diperoleh berukuran besar. Dalam hal ini, ini memiliki 100 angka. Ini adalah situasi di mana mungkin sangat berguna untuk memvisualisasikannya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', color='black')\n",
    "ax.set_ylabel('Actual outputs', color='black')\n",
    "ax.xaxis.set(ticks=range(10))\n",
    "ax.yaxis.set(ticks=range(10))\n",
    "ax.set_ylim(9.5, -0.5)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ini adalah heatmap  yang menggambarkan confusion matrix dengan angka dan warna. Kita dapat melihat bahwa shades of purple menunjukkan angka kecil (seperti 0, 1, atau 2), sedangkan hijau dan kuning menunjukkan angka yang jauh lebih besar (27 ke atas).\n",
    "\n",
    "Angka-angka pada diagonal utama (27, 32,…, 36) menunjukkan jumlah prediksi yang benar dari test set. Misalnya, ada 27 gambar dengan nol, 32 gambar satu, dan seterusnya yang diklasifikasikan dengan benar. Angka lain sesuai dengan prediksi yang salah. Misalnya, angka 1 di baris ketiga dan kolom pertama menunjukkan bahwa ada satu gambar dengan angka 2 yang salah diklasifikasikan sebagai 0.\n",
    "\n",
    "Terakhir, kita bisa mendapatkan laporan klasifikasi sebagai string atau dictionary dengan classification_report():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       0.89      0.91      0.90        35\n",
      "           2       0.94      0.92      0.93        36\n",
      "           3       0.88      0.97      0.92        29\n",
      "           4       1.00      0.97      0.98        30\n",
      "           5       0.97      0.97      0.97        40\n",
      "           6       0.98      0.98      0.98        44\n",
      "           7       0.91      1.00      0.95        39\n",
      "           8       0.94      0.85      0.89        39\n",
      "           9       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.94      0.94      0.94       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **K-Nearest Neighbor (KNN)**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN adalah algoritma non-parametric dan lazy learning algorithm. Non-parametric berarti tidak ada asumsi untuk distribusi data yang mendasarinya. Dengan kata lain, struktur model ditentukan dari dataset. Ini akan sangat membantu dalam praktik di mana sebagian besar kumpulan data dunia nyata tidak mengikuti asumsi teoretis matematis. Lazy algorithm berarti tidak memerlukan training data points untuk pembuatan model. Semua data pelatihan digunakan dalam tahap pengujian. Ini membuat pelatihan lebih cepat dan fase pengujian lebih lambat dan lebih mahal. Fase pengujian yang mahal artinya berdampak pada waktu dan memori. Dalam kasus terburuk, KNN membutuhkan lebih banyak waktu untuk memindai semua titik data dan memindai semua titik data akan membutuhkan lebih banyak memori untuk menyimpan data pelatihan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How does the KNN algorithm work?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di KNN, K adalah jumlah tetangga terdekat/nearest neighbors. Jumlah tetangga adalah faktor penentu utama. K umumnya bilangan ganjil jika jumlah kelasnya 2. Jika K = 1, maka algoritma tersebut dikenal sebagai nearest neighbor algorithm/algoritma tetangga terdekat. Ini kasus yang paling sederhana. Misalkan P1 adalah titik, yang perlu diprediksi oleh label. Pertama, kita menemukan satu titik terdekat ke P1 dan kemudian label titik terdekat ditetapkan ke P1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misalkan P1 adalah titik, yang perlu diprediksi oleh label. Pertama, kita mencari k titik terdekat ke P1 dan kemudian mengklasifikasikan poin berdasarkan suara mayoritas dari k tetangganya. Setiap objek memberikan suara untuk kelasnya dan kelas dengan suara terbanyak diambil sebagai prediksi. Untuk menemukan titik terdekat yang serupa, kita mencari jarak antar titik menggunakan distance measures seperti Euclidean distance, Hamming distance, Manhattan distance dan Minkowski distance. KNN memiliki langkah-langkah dasar sebagai berikut:\n",
    "- Calculate distance\n",
    "- Find closest neighbors\n",
    "- Vote for labels\n",
    "\n",
    "Mari ambil contoh sederhana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/a83/f25/b89/1_efouPJJDe0pRcP9iZV3tsA.png?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita perlu memprediksi status dari Andrew dengan menggunakan Eucledian Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/056/257/295/1604378409638.jpg?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah pertama, hitung Eucledian Distance untuk semua datapoints.\n",
    "\n",
    "dist(d) = Sqrt(x₁-y₁)² + (x₂-y₂)²\n",
    "\n",
    "dist(d) = Sqrt(48 - 25)² + (142000 - 40000)²\n",
    "\n",
    "dist(d) = 102.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/7fe/588/e91/1_KsLDjTb-DXMM9JbUHAroMg_LI.jpg?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumsikan bahwa K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.cdn.thinkific.com/file_uploads/236035/images/550/440/1c6/1_fJ4P2kx3Hh2jTzDrjGYjKA.png?width=1920&dpr=2' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cari nilai minimun dari eucledian distance dan urutkan dari kecil ke besar. Dalam kasus ini dengan k=5 mendapatkan 2 N dan 3 Y. Kita dapat menyimpulkan status dari Andrew adalah Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KNN in Python With scikit-learn: Example 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Defining dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari pertama-tama buat dataset kita sendiri. Di sini kita membutuhkan dua jenis atribut atau kolom dalam data Anda: Feature dan label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning features and label variables\n",
    "\n",
    "# First Feature\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "\n",
    "# Second Feature\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "# Label or target varible\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Encoding data columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berbagai machine learning algorithmsmemerlukan data input numerik, jadi kita perlu merepresentasikan kolom kategorikal dalam kolom numerik.\n",
    "\n",
    "Untuk encode data ini, kita dapat memetakan setiap nilai menjadi sebuah angka. misalnya Overcast:0, Rainy:1, dan Sunny:2.\n",
    "\n",
    "Proses ini dikenal sebagai label encoding, dan sklearn dengan mudah akan melakukannya untuk kita menggunakan Label Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded=le.fit_transform(weather)\n",
    "print(weather_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di sini, kita  mengimpor modul preprocessing dan membuat objek Label Encoder. Dengan menggunakan objek LabelEncoder ini, kita dapat menyesuaikan dan mengubah kolom \"weather\" menjadi kolom numerik.\n",
    "\n",
    "Demikian pula, kita dapat menyandikan temperature dan label ke dalam kolom numerik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "# converting string labels into numbers\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "\n",
    "label=le.fit_transform(play)\n",
    "print(temp_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 : Combining features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di sini, kita akan menggabungkan beberapa kolom atau fitur menjadi satu set data menggunakan fungsi \"zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (2, 1), (0, 1), (1, 2), (1, 0), (1, 0), (0, 0), (2, 2), (2, 0), (1, 2), (2, 2), (0, 2), (0, 1), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "#combinig weather and temp into single listof tuples\n",
    "features=list(zip(weather_encoded,temp_encoded))\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 : Generating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari membangun classifier model KNN.\n",
    "\n",
    "Pertama, impor modul KNeighboursClassifier dan buat classifier object KNN dengan meneruskan argumen jumlah tetangga dalam fungsi KNeighboursClassifier().\n",
    "\n",
    "Kemudian, latih model kita dengan train set menggunakan fit() dan lakukan prediksi pada test set menggunakan predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features,label)\n",
    "\n",
    "#Predict Output\n",
    "predicted = model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada contoh di atas, kita memberikan input [0,2], di mana 0 berarti cuaca mendung/Overcast dan 2 berarti suhu sedang/Mild. Model memprediksi [1], yang artinya play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KNN in Python With scikit-learn: KNN with Multiple Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hingga saat ini, kita telah mempelajari cara membuat pengklasifikasi KNN untuk dua kelas di python menggunakan scikit-learn. Sekarang kita akan belajar tentang KNN dengan banyak kelas.\n",
    "\n",
    "Dalam model, kita dapat menggunakan wine dataset, yang merupakan masalah multi-class classification problem yang sangat terkenal. Data ini merupakan hasil analisis kimiawi wines yang ditanam di wilayah yang sama di Italia menggunakan tiga kultivar berbeda. Analisis menentukan jumlah 13 unsur yang ditemukan di masing-masing dari tiga jenis anggur.\n",
    "\n",
    "Dataset terdiri dari 13 fitur ('alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline') dan target (jenis kultivar).\n",
    "\n",
    "Data ini memiliki tiga jenis kelas kultivar: 'class_0', 'class_1', dan 'class_2'. Di sini, kita dapat membuat model untuk mengklasifikasikan jenis kultivar. Dataset tersedia di pustaka scikit-learn, atau kita juga dapat mengunduhnya dari UCI Machine Learning Library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the required wine dataset from scikit-learn datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "# print the names of the features\n",
    "print(wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# print the label species(class_0, class_1, class_2)\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita periksa 5 record teratas dari set feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(wine.data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita periksa record set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita jelajahi lebih banyak lagi. Kita juga dapat memeriksa bentuk kumpulan data menggunakan shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "# print data(feature)shape\n",
    "print(wine.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "# print target(or label)shape\n",
    "print(wine.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memahami performa model, membagi set data menjadi training set dan a test adalah strategi yang baik.\n",
    "\n",
    "Mari kita pisahkan dataset dengan menggunakan function train_test_split(). Kita harus meneruskan 3 parameter yaitu features, target, dan test_set size. Selain itu, kita dapat menggunakan random_state untuk memilih record secara acak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3) # 70% training and 30% test\n",
    "Generating Model for K=5\n",
    "\n",
    "Mari kita buat model pengklasifikasi KNN untuk k = 5.\n",
    "\n",
    "\n",
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "Model Evaluation for k=5\n",
    "\n",
    "Mari kita perkirakan, seberapa akurat pengklasifikasi atau model dapat memprediksi jenis kultivar.\n",
    "\n",
    "Akurasi dapat dihitung dengan membandingkan actual test set values dan predicted values.\n",
    "\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "Accuracy: 0.6666666666666666\n",
    "Kita mendapat tingkat klasifikasi 66.66%.\n",
    "\n",
    "Untuk evaluasi lebih lanjut, kita juga dapat membuat model untuk jumlah K tetangga yang berbeda.\n",
    "\n",
    "\n",
    "\n",
    "Re-generating Model for K=7\n",
    "\n",
    "Mari kita buat model pengklasifikasi KNN untuk k = 7.\n",
    "\n",
    "\n",
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "Mari kita estimasi lagi, seberapa akurat pengklasifikasi atau model dapat memprediksi jenis kultivar untuk k = 7.\n",
    "\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "Accuracy: 0.6481481481481481\n",
    "Nah, kita mendapat tingkat klasifikasi 64%.\n",
    "\n",
    "Di sini, kita telah meningkatkan jumlah tetangga dalam model dan akurasi menurun. Tapi, ini tidak perlu untuk setiap kasus dimana peningkatan banyak tetangga meningkatkan akurasi.\n",
    "\n",
    "Sekarang saatnya improve model dan mencari tahu nilai k yang optimal.\n",
    "\n",
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):  \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))\n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K')  \n",
    "plt.xlabel('K')  \n",
    "plt.ylabel('Error mean')\n",
    "Text(0, 0.5, 'Error mean')\n",
    "\n",
    "\n",
    "Dari plot tersebut terlihat bahwa error terkecil yang kita dapatkan adalah 0,21 pada K = 25.\n",
    "\n",
    "\n",
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "Accuracy: 0.7962962962962963"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
